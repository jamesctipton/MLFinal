{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8945012",
   "metadata": {},
   "source": [
    "# Analyzing Political Tweets on a Depression Prediction ML Model\n",
    "### Sam Spell, James Tipton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f656d",
   "metadata": {},
   "source": [
    "Political rhetoric and discussions have seemingly become more polarized recently. In history and while reaching adulthood, being able to vote and be a part of politics is a very important role in a stable and healthy society. This project aims to use machine learning to develop a model to predict depression based on a string of text from twitter. Once this model is developed, it can be used to conduct an analysis on political messages sent online. We will be able to draw out patterns in twitter texts that the machine learning model classifies as showing signs of Depression. Another goal of this machine learning model is to extract patterns of text that can be connected to patterns of political messaging if they exist, and to compare this to a temporal aspect. With the changing view on polarized politics, it will be interesting to test if there is a change in the prevalence of messages classified with “depression” throughout different political times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e8f22",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a80da",
   "metadata": {},
   "source": [
    "Step 1: Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55651476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b0c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6525b3",
   "metadata": {},
   "source": [
    "Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1fa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "depress = pd.read_csv(\"depression.csv\")\n",
    "strings = depress[\"clean_text\"]\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "570c52ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>is_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we understand that most people who reply immed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to r depression s check in post a plac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone else instead of sleeping more when depr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ve kind of stuffed around a lot in my life d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep is my greatest and most comforting escap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  is_depression\n",
       "0  we understand that most people who reply immed...              1\n",
       "1  welcome to r depression s check in post a plac...              1\n",
       "2  anyone else instead of sleeping more when depr...              1\n",
       "3  i ve kind of stuffed around a lot in my life d...              1\n",
       "4  sleep is my greatest and most comforting escap...              1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7cda10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8596d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    we understand that most people who reply immed...\n",
       "1    welcome to r depression s check in post a plac...\n",
       "2    anyone else instead of sleeping more when depr...\n",
       "3    i ve kind of stuffed around a lot in my life d...\n",
       "4    sleep is my greatest and most comforting escap...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6deb6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_str = []\n",
    "\n",
    "for string in strings:\n",
    "    words = nltk.word_tokenize(string)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_str = ' '.join(filtered_words)\n",
    "    #print(string)\n",
    "    #print()\n",
    "    #print(filtered_str)\n",
    "    #print()\n",
    "    #print()\n",
    "    #print()\n",
    "    new_str.append(filtered_str)\n",
    "    \n",
    "# print(new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "700da746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7731\n",
      "7731\n"
     ]
    }
   ],
   "source": [
    "print(len(new_str))\n",
    "print(len(strings))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "84d98050c291fbabc1a867c10b51e932498cf5095538e7bdaecff4b39fb1caa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
